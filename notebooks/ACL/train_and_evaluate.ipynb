{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a6d427-a6d1-490f-8018-dde828c4e790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69eb1830-f83f-4bc9-9ec5-404922e5b4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import wandb\n",
    "import string\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import flash_attn\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import util.preprocessing_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc59a037-58d2-4359-b5b1-4a2efbfcf798",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701e8688-82a4-4fc5-ab25-9d0247128f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../../data/dev/processed\")\n",
    "DATASET_NAME = \"medical_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ed7e6b-fb08-4e9f-baed-13e8c37261b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>patient_question</th>\n",
       "      <th>note_excerpt</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>start_char_index</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>brief hospital course during the ercp a pancre...</td>\n",
       "      <td>0</td>\n",
       "      <td>brief hospital course</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>brief hospital course during the ercp a pancre...</td>\n",
       "      <td>1</td>\n",
       "      <td>during the ercp a pancreatic stent was require...</td>\n",
       "      <td>essential</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>brief hospital course during the ercp a pancre...</td>\n",
       "      <td>2</td>\n",
       "      <td>however due to the patients elevated inr no sp...</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>244</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>brief hospital course during the ercp a pancre...</td>\n",
       "      <td>3</td>\n",
       "      <td>frank pus was noted to be draining from the co...</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>338</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>brief hospital course during the ercp a pancre...</td>\n",
       "      <td>4</td>\n",
       "      <td>the vancomycin was discontinued</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>490</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id                                   patient_question  \\\n",
       "0        1  my question is if the sludge was there does no...   \n",
       "1        1  my question is if the sludge was there does no...   \n",
       "2        1  my question is if the sludge was there does no...   \n",
       "3        1  my question is if the sludge was there does no...   \n",
       "4        1  my question is if the sludge was there does no...   \n",
       "\n",
       "                                        note_excerpt  sentence_id  \\\n",
       "0  brief hospital course during the ercp a pancre...            0   \n",
       "1  brief hospital course during the ercp a pancre...            1   \n",
       "2  brief hospital course during the ercp a pancre...            2   \n",
       "3  brief hospital course during the ercp a pancre...            3   \n",
       "4  brief hospital course during the ercp a pancre...            4   \n",
       "\n",
       "                                       sentence_text     relevance  \\\n",
       "0                              brief hospital course  not-relevant   \n",
       "1  during the ercp a pancreatic stent was require...     essential   \n",
       "2  however due to the patients elevated inr no sp...  not-relevant   \n",
       "3  frank pus was noted to be draining from the co...  not-relevant   \n",
       "4                    the vancomycin was discontinued  not-relevant   \n",
       "\n",
       "   start_char_index  length  \n",
       "0                 0      22  \n",
       "1                 0     243  \n",
       "2               244      93  \n",
       "3               338     151  \n",
       "4               490      32  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_DIR / DATASET_NAME)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940c0345-97fe-4fb3-a038-3abca561e836",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1033257/2774396375.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(aggregate_case)\n"
     ]
    }
   ],
   "source": [
    "# Group by case_id and build sentence list + label list\n",
    "def aggregate_case(group):\n",
    "    sentences = group[\"sentence_text\"].tolist()\n",
    "    labels = [1 if rel in [\"essential\", \"relevant\"] else 0 for rel in group[\"relevance\"]]\n",
    "    return pd.Series({\n",
    "        \"question\": group[\"patient_question\"].iloc[0],\n",
    "        \"sentences\": sentences,\n",
    "        \"labels\": labels\n",
    "    })\n",
    "\n",
    "# Select only needed columns before grouping to silence the warning\n",
    "data = (\n",
    "    data[[\"case_id\", \"patient_question\", \"sentence_text\", \"relevance\"]]\n",
    "    .groupby(\"case_id\")\n",
    "    .apply(aggregate_case)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691c75c7-0204-4d55-9f6d-e6e96d64a36d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>question</th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>[brief hospital course, during the ercp a panc...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dad given multiple shots of lasciks after he w...</td>\n",
       "      <td>[brief hospital course, acute diastolic heart ...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>he is continously irritated and has headache w...</td>\n",
       "      <td>[discharge instructions you were admitted to t...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>my doctor performed a cardiac catherization</td>\n",
       "      <td>[history of present illness, on the cardiology...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>i overdosed october 4th on trihexyphenidyl tho...</td>\n",
       "      <td>[brief hospital course,  bipolar do ptsd schiz...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id                                           question  \\\n",
       "0        1  my question is if the sludge was there does no...   \n",
       "1        2  dad given multiple shots of lasciks after he w...   \n",
       "2        3  he is continously irritated and has headache w...   \n",
       "3        4        my doctor performed a cardiac catherization   \n",
       "4        5  i overdosed october 4th on trihexyphenidyl tho...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [brief hospital course, during the ercp a panc...   \n",
       "1  [brief hospital course, acute diastolic heart ...   \n",
       "2  [discharge instructions you were admitted to t...   \n",
       "3  [history of present illness, on the cardiology...   \n",
       "4  [brief hospital course,  bipolar do ptsd schiz...   \n",
       "\n",
       "                                              labels  \n",
       "0                        [0, 1, 0, 0, 0, 1, 1, 1, 0]  \n",
       "1                  [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0]  \n",
       "2                     [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b981b61-99b9-4a71-b795-0b21325dcf37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brief hospital course',\n",
       " 'during the ercp a pancreatic stent was required to facilitate access to the biliary system removed at the end of the procedure and a common bile duct stent was placed to allow drainage of the biliary obstruction caused by stones and sludge',\n",
       " 'however due to the patients elevated inr no sphincterotomy or stone removal was performed',\n",
       " 'frank pus was noted to be draining from the common bile duct and postercp it was recommended that the patient remain on iv zosyn for at least a week',\n",
       " 'the vancomycin was discontinued',\n",
       " 'on hospital day 4 postprocedure day 3 the patient returned to ercp for reevaluation of her biliary stent as her lfts and bilirubin continued an upward trend',\n",
       " 'on ercp the previous biliary stent was noted to be acutely obstructed by biliary sludge and stones',\n",
       " 'as the patients inr was normalized to 12 a sphincterotomy was safely performed with removal of several biliary stones in addition to the common bile duct stent',\n",
       " 'at the conclusion of the procedure retrograde cholangiogram was negative for filling defects']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b662121-e972-4649-bc2d-de0e4b40d709",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25cff802-3968-427e-b0a0-6b08c15b16a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122d87a7-9128-4b26-b56e-f11094d98a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = util.mask_on_sentence_level(data, window=WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd64aec9-9688-4a31-8c5e-e93ab96004f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>target_sentence</th>\n",
       "      <th>target_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>[START] brief hospital course [END]. during th...</td>\n",
       "      <td>brief hospital course</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>brief hospital course. [START] during the ercp...</td>\n",
       "      <td>during the ercp a pancreatic stent was require...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>brief hospital course. during the ercp a pancr...</td>\n",
       "      <td>however due to the patients elevated inr no sp...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>during the ercp a pancreatic stent was require...</td>\n",
       "      <td>frank pus was noted to be draining from the co...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my question is if the sludge was there does no...</td>\n",
       "      <td>however due to the patients elevated inr no sp...</td>\n",
       "      <td>the vancomycin was discontinued</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  my question is if the sludge was there does no...   \n",
       "1  my question is if the sludge was there does no...   \n",
       "2  my question is if the sludge was there does no...   \n",
       "3  my question is if the sludge was there does no...   \n",
       "4  my question is if the sludge was there does no...   \n",
       "\n",
       "                                             context  \\\n",
       "0  [START] brief hospital course [END]. during th...   \n",
       "1  brief hospital course. [START] during the ercp...   \n",
       "2  brief hospital course. during the ercp a pancr...   \n",
       "3  during the ercp a pancreatic stent was require...   \n",
       "4  however due to the patients elevated inr no sp...   \n",
       "\n",
       "                                     target_sentence  target_index  label  \n",
       "0                              brief hospital course             0      0  \n",
       "1  during the ercp a pancreatic stent was require...             1      1  \n",
       "2  however due to the patients elevated inr no sp...             2      0  \n",
       "3  frank pus was noted to be draining from the co...             3      0  \n",
       "4                    the vancomycin was discontinued             4      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f560285-b6dc-4001-be47-463c87264fb6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2fece48-ee40-4c5c-958f-df9cedc97641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = Path(\"../../models\")\n",
    "model_name = \"BioMedBert-W2\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir / model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir / model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfe327e0-5671-4d61-a8cb-9ad29667a4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f6064-1fd5-49b1-83c6-7fcdd98d665e",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca370c2e-4ebd-4598-ab09-7a2efe8b3ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "CONTEXT_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07cc1971-20fe-4ef5-a177-17606c8357af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_test = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "649ab135-1e4d-4e22-a475-f11b706bbbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c8c48ba6b4441d8c86a88fe41a14bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(total=(len(dataset_test)),\n",
    "                    desc=\"Tokenizing\", position=0, leave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df12ea36-4399-4227-8c0e-36fc99e7e7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_batch(batch):\n",
    "    encodings = tokenizer(\n",
    "        batch[\"question\"],\n",
    "        batch[\"context\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=CONTEXT_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": encodings[\"input_ids\"].tolist(),\n",
    "        \"attention_mask\": encodings[\"attention_mask\"].tolist(),\n",
    "        \"labels\": batch[\"label\"]\n",
    "    }\n",
    "\n",
    "def tokenize_with_progress(batch):\n",
    "    out = tokenize_batch(batch)\n",
    "    progress_bar.update(len(batch[\"question\"]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feaf9a57-e19a-4a08-b48a-b4cb1f139f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_with_progress at 0x1553ddd04ca0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d1e8dc6fed43acbbbb4e57a964c2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset_test = dataset_test.map(tokenize_with_progress, batched=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d57f9cc-0fa9-4857-875a-3c7b3bd4e7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d99482-5bc1-47e2-be05-a7774e6112c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dataset_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59aec735-814c-4d0e-ae52-924a36740949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(tokenized_dataset_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8c07cce-6866-4c0c-bccd-8f5974b63ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': torch.Size([64, 512]), 'attention_mask': torch.Size([64, 512]), 'labels': torch.Size([64])}\n"
     ]
    }
   ],
   "source": [
    "# Check one batch\n",
    "batch = next(iter(test_dataloader))\n",
    "print({key: value.shape for key, value in batch.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48e84b65-a467-45ab-ba09-1746157f2efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Test Set -----\n",
      "Dataset({\n",
      "    features: ['question', 'context', 'target_sentence', 'target_index', 'label', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 428\n",
      "})\n",
      "['question', 'context', 'target_sentence', 'target_index', 'label', 'input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "print(\"----- Test Set -----\")\n",
    "print(tokenized_dataset_test)\n",
    "print(tokenized_dataset_test.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f3f8c-64cf-4610-bf90-f2e52a4d0304",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5afcf31-8f13-4cc4-9343-0b1ec5c849b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776432b79fea414182271e557445cb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m input_ids \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      9\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 10\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlabels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)  \u001B[38;5;66;03m# Get binary label (1 = relevant)\u001B[39;00m\n\u001B[1;32m     12\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(input_ids\u001B[38;5;241m=\u001B[39minput_ids, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask)\n\u001B[1;32m     13\u001B[0m probs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msigmoid(outputs\u001B[38;5;241m.\u001B[39mlogits)\u001B[38;5;241m.\u001B[39msqueeze()  \u001B[38;5;66;03m# Shape: [batch_size]\u001B[39;00m\n",
      "\u001B[0;31mIndexError\u001B[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "threshold = 0.3\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"][:, 1].to(device)  # Get binary label (1 = relevant)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probs = torch.sigmoid(outputs.logits).squeeze()  # Shape: [batch_size]\n",
    "\n",
    "        preds = (probs > threshold).long()\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy().tolist())\n",
    "        all_labels.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "print(classification_report(all_labels, all_preds, digits=4, output_dict=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28a4d1a3-f98a-4d1d-9eaf-5845f5fe90ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428,)\n",
      "(428, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(all_labels).shape)\n",
    "print(np.array(all_preds).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adc3b180-976e-4ca1-9d5f-43d6d498954c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mclassification_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdigits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    212\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    213\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    214\u001B[0m         )\n\u001B[1;32m    215\u001B[0m     ):\n\u001B[0;32m--> 216\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    221\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    222\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    224\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    225\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    226\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2671\u001B[0m, in \u001B[0;36mclassification_report\u001B[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001B[0m\n\u001B[1;32m   2563\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001B[39;00m\n\u001B[1;32m   2564\u001B[0m \n\u001B[1;32m   2565\u001B[0m \u001B[38;5;124;03mRead more in the :ref:`User Guide <classification_report>`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2667\u001B[0m \u001B[38;5;124;03m<BLANKLINE>\u001B[39;00m\n\u001B[1;32m   2668\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2670\u001B[0m y_true, y_pred \u001B[38;5;241m=\u001B[39m attach_unique(y_true, y_pred)\n\u001B[0;32m-> 2671\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2673\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2674\u001B[0m     labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:107\u001B[0m, in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m    104\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 107\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    108\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    109\u001B[0m             type_true, type_pred\n\u001B[1;32m    110\u001B[0m         )\n\u001B[1;32m    111\u001B[0m     )\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[1;32m    114\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[0;31mValueError\u001B[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "classification_report(all_labels, all_preds, digits=4, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa7b9f98-bf7c-4790-9ada-08c8f1a62de1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m report \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[43mclassification_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdigits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39mtranspose()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    212\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    213\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    214\u001B[0m         )\n\u001B[1;32m    215\u001B[0m     ):\n\u001B[0;32m--> 216\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    221\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    222\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    224\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    225\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    226\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2671\u001B[0m, in \u001B[0;36mclassification_report\u001B[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001B[0m\n\u001B[1;32m   2563\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001B[39;00m\n\u001B[1;32m   2564\u001B[0m \n\u001B[1;32m   2565\u001B[0m \u001B[38;5;124;03mRead more in the :ref:`User Guide <classification_report>`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2667\u001B[0m \u001B[38;5;124;03m<BLANKLINE>\u001B[39;00m\n\u001B[1;32m   2668\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2670\u001B[0m y_true, y_pred \u001B[38;5;241m=\u001B[39m attach_unique(y_true, y_pred)\n\u001B[0;32m-> 2671\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2673\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2674\u001B[0m     labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:107\u001B[0m, in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m    104\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 107\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    108\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    109\u001B[0m             type_true, type_pred\n\u001B[1;32m    110\u001B[0m         )\n\u001B[1;32m    111\u001B[0m     )\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[1;32m    114\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[0;31mValueError\u001B[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "report = pd.DataFrame(classification_report(all_labels, all_preds, digits=4, output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b349ba1-4c41-476a-ad1f-1a1600374dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c38af4-2281-42ef-be78-8431e208f21b",
   "metadata": {},
   "source": [
    "**Window-Size: 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72b52b58-2568-453e-85b0-63d477177fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.699482</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>138.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.682243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.611646</td>\n",
       "      <td>0.545227</td>\n",
       "      <td>0.521631</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.642840</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.620070</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.699482  0.931034  0.798817  290.000000\n",
       "1              0.523810  0.159420  0.244444  138.000000\n",
       "accuracy       0.682243  0.682243  0.682243    0.682243\n",
       "macro avg      0.611646  0.545227  0.521631  428.000000\n",
       "weighted avg   0.642840  0.682243  0.620070  428.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0996811c-cf70-4c12-b6a2-d4937e607199",
   "metadata": {},
   "source": [
    "**Window-Size: 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9642b78-73a3-4d15-9f72-715e374bc19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.937931</td>\n",
       "      <td>0.802360</td>\n",
       "      <td>290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>138.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.686916</td>\n",
       "      <td>0.686916</td>\n",
       "      <td>0.686916</td>\n",
       "      <td>0.686916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.625515</td>\n",
       "      <td>0.548676</td>\n",
       "      <td>0.524775</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.652334</td>\n",
       "      <td>0.686916</td>\n",
       "      <td>0.623357</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.701031  0.937931  0.802360  290.000000\n",
       "1              0.550000  0.159420  0.247191  138.000000\n",
       "accuracy       0.686916  0.686916  0.686916    0.686916\n",
       "macro avg      0.625515  0.548676  0.524775  428.000000\n",
       "weighted avg   0.652334  0.686916  0.623357  428.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043526f-8c0a-4203-8615-d01963b79f2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Window-Size: 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bfbd4da-ef3f-419b-8448-045f149750e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710594</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.812408</td>\n",
       "      <td>290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.290503</td>\n",
       "      <td>138.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.703271</td>\n",
       "      <td>0.703271</td>\n",
       "      <td>0.703271</td>\n",
       "      <td>0.703271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.672370</td>\n",
       "      <td>0.568341</td>\n",
       "      <td>0.551455</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.685945</td>\n",
       "      <td>0.703271</td>\n",
       "      <td>0.644130</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.710594  0.948276  0.812408  290.000000\n",
       "1              0.634146  0.188406  0.290503  138.000000\n",
       "accuracy       0.703271  0.703271  0.703271    0.703271\n",
       "macro avg      0.672370  0.568341  0.551455  428.000000\n",
       "weighted avg   0.685945  0.703271  0.644130  428.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae796d-475e-49c9-9dd9-05edb8030d6f",
   "metadata": {},
   "source": [
    "**Window-Size: 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "de32dad2-f7f6-4afa-9f1c-65c78fb8509e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.700521</td>\n",
       "      <td>0.927586</td>\n",
       "      <td>0.798220</td>\n",
       "      <td>290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.252747</td>\n",
       "      <td>138.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.682243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.611624</td>\n",
       "      <td>0.547126</td>\n",
       "      <td>0.525483</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.643195</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.622343</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.700521  0.927586  0.798220  290.000000\n",
       "1              0.522727  0.166667  0.252747  138.000000\n",
       "accuracy       0.682243  0.682243  0.682243    0.682243\n",
       "macro avg      0.611624  0.547126  0.525483  428.000000\n",
       "weighted avg   0.643195  0.682243  0.622343  428.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa339458-0d34-426c-9e72-3019479dbf48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
