{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1325a5c3",
   "metadata": {},
   "source": [
    "# Train Classifier Head for Span Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7a0f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ast\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4debce22",
   "metadata": {},
   "source": [
    "# Evaluate Sentence-Level Span Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f61b7-f60c-4d7b-9d74-786dfe73945e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5acac-1b27-4b7c-b4b2-2558d5c2aaef",
   "metadata": {
    "tags": []
   },
   "source": [
    "Check versions of important packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e47356-f3ed-4721-81c7-8ea1264d9efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA version: 12.4\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56aa48e7-fe59-4b94-ab49-b27ee55efdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/miniforge3/bin/python3.10\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ad7ff",
   "metadata": {},
   "source": [
    "## 1. Load sentence-level test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6b890ee-56f8-415e-a2c9-b50c57051ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_data_path = Path(\"../../data/dev/processed\")\n",
    "train_df = pd.read_csv(input_data_path / \"pubmedqa_train.csv\")\n",
    "test_df = pd.read_csv(input_data_path / \"pubmedqa_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44822ab8-a189-4e85-bb28-bebdf4608400",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sentences and labels are still stringified lists --> back to actual Python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec498def-f93f-4a05-a295-aa4325c9b365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply literal_eval to parse strings into actual lists\n",
    "train_df[\"sentences\"] = train_df[\"sentences\"].apply(ast.literal_eval)\n",
    "train_df[\"labels\"] = train_df[\"labels\"].apply(ast.literal_eval)\n",
    "\n",
    "test_df[\"sentences\"] = test_df[\"sentences\"].apply(ast.literal_eval)\n",
    "test_df[\"labels\"] = test_df[\"labels\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d35b87b-b6d3-4e45-b444-9cfad7e9d48c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is there a functional neural correlate of indi...</td>\n",
       "      <td>[the present study tested whether individuals ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can we use the omron t9p automated blood press...</td>\n",
       "      <td>[recent events in our hospital combined with i...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intraabdominal vascular injury are we getting ...</td>\n",
       "      <td>[intraabdominal vascular injury iavi as a resu...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hand grip and pinch strength in patients with ...</td>\n",
       "      <td>[the hand grip strength test and pinch was sig...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is canada ready for patient accessible electro...</td>\n",
       "      <td>[access to personal health information through...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791</th>\n",
       "      <td>does postmastectomy radiotherapy affect the ou...</td>\n",
       "      <td>[the decision to perform immediate deep inferi...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9792</th>\n",
       "      <td>risk of reoperation within 90 days of liver tr...</td>\n",
       "      <td>[overall 90day reoperation rate after lt was 2...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>is the menopause rating scale accurate for dia...</td>\n",
       "      <td>[to evaluate the accuracy of the menopause rat...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9794</th>\n",
       "      <td>can snow depth be used to predict the distribu...</td>\n",
       "      <td>[the svalbard endemic aphid acyrthosiphon sval...</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>can sevoflurane save time in routine clincal use</td>\n",
       "      <td>[18 cases were included halo n  8sevo n  10 no...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9796 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     is there a functional neural correlate of indi...   \n",
       "1     can we use the omron t9p automated blood press...   \n",
       "2     intraabdominal vascular injury are we getting ...   \n",
       "3     hand grip and pinch strength in patients with ...   \n",
       "4     is canada ready for patient accessible electro...   \n",
       "...                                                 ...   \n",
       "9791  does postmastectomy radiotherapy affect the ou...   \n",
       "9792  risk of reoperation within 90 days of liver tr...   \n",
       "9793  is the menopause rating scale accurate for dia...   \n",
       "9794  can snow depth be used to predict the distribu...   \n",
       "9795   can sevoflurane save time in routine clincal use   \n",
       "\n",
       "                                              sentences  \\\n",
       "0     [the present study tested whether individuals ...   \n",
       "1     [recent events in our hospital combined with i...   \n",
       "2     [intraabdominal vascular injury iavi as a resu...   \n",
       "3     [the hand grip strength test and pinch was sig...   \n",
       "4     [access to personal health information through...   \n",
       "...                                                 ...   \n",
       "9791  [the decision to perform immediate deep inferi...   \n",
       "9792  [overall 90day reoperation rate after lt was 2...   \n",
       "9793  [to evaluate the accuracy of the menopause rat...   \n",
       "9794  [the svalbard endemic aphid acyrthosiphon sval...   \n",
       "9795  [18 cases were included halo n  8sevo n  10 no...   \n",
       "\n",
       "                                                 labels  \n",
       "0            [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0]  \n",
       "1     [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...  \n",
       "2     [1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, ...  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...  \n",
       "...                                                 ...  \n",
       "9791  [1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, ...  \n",
       "9792  [1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "9793  [1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...  \n",
       "9794  [0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "9795  [1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "\n",
       "[9796 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129b1e7",
   "metadata": {},
   "source": [
    "## 2. Load the pretrained model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f80127a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Some weights of ModernBertModel were not initialized from the model checkpoint at KRLabsOrg/chiliground-base-modernbert-v1 and are newly initialized: ['embeddings.norm.weight', 'embeddings.tok_embeddings.weight', 'final_norm.weight', 'layers.0.attn.Wo.weight', 'layers.0.attn.Wqkv.weight', 'layers.0.mlp.Wi.weight', 'layers.0.mlp.Wo.weight', 'layers.0.mlp_norm.weight', 'layers.1.attn.Wo.weight', 'layers.1.attn.Wqkv.weight', 'layers.1.attn_norm.weight', 'layers.1.mlp.Wi.weight', 'layers.1.mlp.Wo.weight', 'layers.1.mlp_norm.weight', 'layers.10.attn.Wo.weight', 'layers.10.attn.Wqkv.weight', 'layers.10.attn_norm.weight', 'layers.10.mlp.Wi.weight', 'layers.10.mlp.Wo.weight', 'layers.10.mlp_norm.weight', 'layers.11.attn.Wo.weight', 'layers.11.attn.Wqkv.weight', 'layers.11.attn_norm.weight', 'layers.11.mlp.Wi.weight', 'layers.11.mlp.Wo.weight', 'layers.11.mlp_norm.weight', 'layers.12.attn.Wo.weight', 'layers.12.attn.Wqkv.weight', 'layers.12.attn_norm.weight', 'layers.12.mlp.Wi.weight', 'layers.12.mlp.Wo.weight', 'layers.12.mlp_norm.weight', 'layers.13.attn.Wo.weight', 'layers.13.attn.Wqkv.weight', 'layers.13.attn_norm.weight', 'layers.13.mlp.Wi.weight', 'layers.13.mlp.Wo.weight', 'layers.13.mlp_norm.weight', 'layers.14.attn.Wo.weight', 'layers.14.attn.Wqkv.weight', 'layers.14.attn_norm.weight', 'layers.14.mlp.Wi.weight', 'layers.14.mlp.Wo.weight', 'layers.14.mlp_norm.weight', 'layers.15.attn.Wo.weight', 'layers.15.attn.Wqkv.weight', 'layers.15.attn_norm.weight', 'layers.15.mlp.Wi.weight', 'layers.15.mlp.Wo.weight', 'layers.15.mlp_norm.weight', 'layers.16.attn.Wo.weight', 'layers.16.attn.Wqkv.weight', 'layers.16.attn_norm.weight', 'layers.16.mlp.Wi.weight', 'layers.16.mlp.Wo.weight', 'layers.16.mlp_norm.weight', 'layers.17.attn.Wo.weight', 'layers.17.attn.Wqkv.weight', 'layers.17.attn_norm.weight', 'layers.17.mlp.Wi.weight', 'layers.17.mlp.Wo.weight', 'layers.17.mlp_norm.weight', 'layers.18.attn.Wo.weight', 'layers.18.attn.Wqkv.weight', 'layers.18.attn_norm.weight', 'layers.18.mlp.Wi.weight', 'layers.18.mlp.Wo.weight', 'layers.18.mlp_norm.weight', 'layers.19.attn.Wo.weight', 'layers.19.attn.Wqkv.weight', 'layers.19.attn_norm.weight', 'layers.19.mlp.Wi.weight', 'layers.19.mlp.Wo.weight', 'layers.19.mlp_norm.weight', 'layers.2.attn.Wo.weight', 'layers.2.attn.Wqkv.weight', 'layers.2.attn_norm.weight', 'layers.2.mlp.Wi.weight', 'layers.2.mlp.Wo.weight', 'layers.2.mlp_norm.weight', 'layers.20.attn.Wo.weight', 'layers.20.attn.Wqkv.weight', 'layers.20.attn_norm.weight', 'layers.20.mlp.Wi.weight', 'layers.20.mlp.Wo.weight', 'layers.20.mlp_norm.weight', 'layers.21.attn.Wo.weight', 'layers.21.attn.Wqkv.weight', 'layers.21.attn_norm.weight', 'layers.21.mlp.Wi.weight', 'layers.21.mlp.Wo.weight', 'layers.21.mlp_norm.weight', 'layers.3.attn.Wo.weight', 'layers.3.attn.Wqkv.weight', 'layers.3.attn_norm.weight', 'layers.3.mlp.Wi.weight', 'layers.3.mlp.Wo.weight', 'layers.3.mlp_norm.weight', 'layers.4.attn.Wo.weight', 'layers.4.attn.Wqkv.weight', 'layers.4.attn_norm.weight', 'layers.4.mlp.Wi.weight', 'layers.4.mlp.Wo.weight', 'layers.4.mlp_norm.weight', 'layers.5.attn.Wo.weight', 'layers.5.attn.Wqkv.weight', 'layers.5.attn_norm.weight', 'layers.5.mlp.Wi.weight', 'layers.5.mlp.Wo.weight', 'layers.5.mlp_norm.weight', 'layers.6.attn.Wo.weight', 'layers.6.attn.Wqkv.weight', 'layers.6.attn_norm.weight', 'layers.6.mlp.Wi.weight', 'layers.6.mlp.Wo.weight', 'layers.6.mlp_norm.weight', 'layers.7.attn.Wo.weight', 'layers.7.attn.Wqkv.weight', 'layers.7.attn_norm.weight', 'layers.7.mlp.Wi.weight', 'layers.7.mlp.Wo.weight', 'layers.7.mlp_norm.weight', 'layers.8.attn.Wo.weight', 'layers.8.attn.Wqkv.weight', 'layers.8.attn_norm.weight', 'layers.8.mlp.Wi.weight', 'layers.8.mlp.Wo.weight', 'layers.8.mlp_norm.weight', 'layers.9.attn.Wo.weight', 'layers.9.attn.Wqkv.weight', 'layers.9.attn_norm.weight', 'layers.9.mlp.Wi.weight', 'layers.9.mlp.Wo.weight', 'layers.9.mlp_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"KRLabsOrg/chiliground-base-modernbert-v1\"\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "classifier = torch.nn.Linear(model.config.hidden_size, 2)  # attach simple head\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "classifier.to(device)\n",
    "# switch them into evaluation/inference mode\n",
    "model.eval()\n",
    "classifier.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3070a2a",
   "metadata": {},
   "source": [
    "## 3. Encode sentences with boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "558197f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_sentences(question, sentences, tokenizer, max_length=512):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    sentence_boundaries = []\n",
    "\n",
    "    q_ids = tokenizer.encode(question, add_special_tokens=True, truncation=True, max_length=max_length)\n",
    "    input_ids.extend(q_ids[:-1])\n",
    "    attention_mask.extend([1]*len(q_ids[:-1]))\n",
    "\n",
    "    for sent in sentences:\n",
    "        sent_ids = tokenizer.encode(sent, add_special_tokens=False, truncation=True, max_length=max_length)\n",
    "        if len(input_ids) + len(sent_ids) + 1 > max_length:\n",
    "            break\n",
    "        sentence_boundaries.append((len(input_ids), len(input_ids) + len(sent_ids) - 1))\n",
    "        input_ids.append(tokenizer.sep_token_id)\n",
    "        attention_mask.append(1)\n",
    "        input_ids.extend(sent_ids)\n",
    "        attention_mask.extend([1]*len(sent_ids))\n",
    "\n",
    "    input_ids.append(tokenizer.sep_token_id)\n",
    "    attention_mask.append(1)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids).unsqueeze(0).to(device),\n",
    "        \"attention_mask\": torch.tensor(attention_mask).unsqueeze(0).to(device),\n",
    "        \"sentence_boundaries\": [sentence_boundaries]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7795c77",
   "metadata": {},
   "source": [
    "## 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0626de27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b5ba6e2538410a9705d6f149df68f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Evaluating\"):\n",
    "        question = row[\"question\"]\n",
    "        sentences = row[\"sentences\"]\n",
    "        labels = row[\"labels\"]\n",
    "\n",
    "        encoded = encode_sentences(question, sentences, tokenizer)\n",
    "        outputs = model(input_ids=encoded[\"input_ids\"], attention_mask=encoded[\"attention_mask\"])\n",
    "        last_hidden = outputs.last_hidden_state\n",
    "\n",
    "        preds = []\n",
    "        for start, end in encoded[\"sentence_boundaries\"][0]:\n",
    "            span_repr = last_hidden[0, start:end+1].mean(dim=0)\n",
    "            logit = classifier(span_repr)\n",
    "            pred = torch.argmax(logit).item()\n",
    "            preds.append(pred)\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels[:len(preds)])  # account for truncation\n",
    "\n",
    "report = pd.DataFrame(classification_report(all_labels, all_preds, digits=4, output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a7beb15-481d-4042-b472-8bd20d913806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = pd.DataFrame(classification_report(all_labels, all_preds, digits=4, output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "191d896b-66cd-4dbb-9b55-20daa29cbd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566072</td>\n",
       "      <td>0.513880</td>\n",
       "      <td>0.538715</td>\n",
       "      <td>12104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430507</td>\n",
       "      <td>0.482639</td>\n",
       "      <td>0.455085</td>\n",
       "      <td>9216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.500375</td>\n",
       "      <td>0.500375</td>\n",
       "      <td>0.500375</td>\n",
       "      <td>0.500375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.498290</td>\n",
       "      <td>0.498259</td>\n",
       "      <td>0.496900</td>\n",
       "      <td>21320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.507471</td>\n",
       "      <td>0.500375</td>\n",
       "      <td>0.502564</td>\n",
       "      <td>21320.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "0              0.566072  0.513880  0.538715  12104.000000\n",
       "1              0.430507  0.482639  0.455085   9216.000000\n",
       "accuracy       0.500375  0.500375  0.500375      0.500375\n",
       "macro avg      0.498290  0.498259  0.496900  21320.000000\n",
       "weighted avg   0.507471  0.500375  0.502564  21320.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99178b6-6a71-43ba-8f7f-dfc1716d264a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
