{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-Enriched Processor Testing\n",
    "\n",
    "This notebook tests the new context-enriched chunking approach that adds hierarchical section context to each chunk for better RAG retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/paulschmitt/DataspellProjects/verbatim-rag\n",
      "‚úÖ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Fix OpenMP conflict (common with ML libraries on macOS)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n"
     ]
    }
   ],
   "source": [
    "from verbatim_rag.ingestion.context_enriched_processor import ContextEnrichedProcessor, ContextEnrichedChunk\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Basic Context-Enriched Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulschmitt/miniforge3/envs/verbatim-rag-2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document processed successfully!\n",
      "Title: Verbatim RAG ACL Paper\n",
      "Chunks: 57\n",
      "Content type: DocumentType.PDF\n"
     ]
    }
   ],
   "source": [
    "# Test with the academic paper\n",
    "pdf_path = project_root / \"data\" / \"acl_papers\" / \"VERBATIM_RAG_ACL.pdf\"\n",
    "\n",
    "# Create context-enriched processor\n",
    "processor = ContextEnrichedProcessor.for_rag(chunk_size=512)\n",
    "\n",
    "# Process document\n",
    "document = processor.process_file(pdf_path, title=\"Verbatim RAG ACL Paper\")\n",
    "\n",
    "print(f\"‚úÖ Document processed successfully!\")\n",
    "print(f\"Title: {document.title}\")\n",
    "print(f\"Chunks: {len(document.chunks)}\")\n",
    "print(f\"Content type: {document.content_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Examine Context-Enriched Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Context-Enriched Chunk Analysis:\n",
      "Total chunks: 57\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Context-Enriched Chunk Analysis:\")\n",
    "print(f\"Total chunks: {len(document.chunks)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù First 10 Chunks with Context:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['1 Introduction']\n",
      "Context: Section: 1 Introduction\n",
      "Content: Modern question-answering (QA) and retrievalaugmented generation (RAG) systems play a vital role in ...\n",
      "Enhanced: Section: 1 Introduction | Modern question-answering (QA) and retrievalaugmented generation (RAG) systems play a vital role in many high-stakes domains...\n",
      "Citation: 1 Introduction\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['1 Introduction']\n",
      "Context: Section: 1 Introduction\n",
      "Content: incorrect information, commonly referred to as hallucinations (Ji et al., 2023; Madsen et al., 2024)...\n",
      "Enhanced: Section: 1 Introduction | incorrect information, commonly referred to as hallucinations (Ji et al., 2023; Madsen et al., 2024). We argue that a reliab...\n",
      "Citation: 1 Introduction\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['1 Introduction']\n",
      "Context: Section: 1 Introduction\n",
      "Content: trained generation , dynamically creating answer templates filled exclu-\n",
      "\n",
      "We participated in the Arc...\n",
      "Enhanced: Section: 1 Introduction | trained generation , dynamically creating answer templates filled exclu-\n",
      "\n",
      "We participated in the ArchEHR-QA 2025 shared task...\n",
      "Citation: 1 Introduction\n",
      "\n",
      "--- Chunk 4 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['1 Introduction']\n",
      "Context: Section: 1 Introduction\n",
      "Content: arner et al., 2024), achieving performance comparable to the LLM extractor. Both extractors were the...\n",
      "Enhanced: Section: 1 Introduction | arner et al., 2024), achieving performance comparable to the LLM extractor. Both extractors were then fed into the same LLM ...\n",
      "Citation: 1 Introduction\n",
      "\n",
      "--- Chunk 5 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['1 Introduction']\n",
      "Context: Section: 1 Introduction\n",
      "Content: d train custom models. Additionally, we are releasing all the code on GitHub 2 under the MIT License...\n",
      "Enhanced: Section: 1 Introduction | d train custom models. Additionally, we are releasing all the code on GitHub 2 under the MIT License.\n",
      "\n",
      "The remainder of the ...\n",
      "Citation: 1 Introduction\n",
      "\n",
      "--- Chunk 6 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['2 Background', '2.1 Dataset']\n",
      "Context: Section: 2 Background | Subsection: 2.1 Dataset\n",
      "Content: Early clinical QA datasets such as emrQA (Pampari et al., 2018) and CliCR (≈†uster and Daelemans, 201...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.1 Dataset | Early clinical QA datasets such as emrQA (Pampari et al., 2018) and CliCR (≈†uster and Daelemans, 201...\n",
      "Citation: 2 Background ‚Üí 2.1 Dataset\n",
      "\n",
      "--- Chunk 7 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['2 Background', '2.1 Dataset']\n",
      "Context: Section: 2 Background | Subsection: 2.1 Dataset\n",
      "Content: sentence-level as essential , supplementary , or irrelevant . Answers must be concise (under 75 word...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.1 Dataset | sentence-level as essential , supplementary , or irrelevant . Answers must be concise (under 75 word...\n",
      "Citation: 2 Background ‚Üí 2.1 Dataset\n",
      "\n",
      "--- Chunk 8 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['2 Background', '2.2 Limitations of Standard RAG']\n",
      "Context: Section: 2 Background | Subsection: 2.2 Limitations of Standard RAG\n",
      "Content: Standard RAG models, despite external grounding, still frequently hallucinate unsupported or contrad...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.2 Limitations of Standard RAG | Standard RAG models, despite external grounding, still frequently hallucinate un...\n",
      "Citation: 2 Background ‚Üí 2.2 Limitations of Standard RAG\n",
      "\n",
      "--- Chunk 9 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['2 Background', '2.2 Limitations of Standard RAG']\n",
      "Context: Section: 2 Background | Subsection: 2.2 Limitations of Standard RAG\n",
      "Content: ano and Smith, 2019; Jain and Wallace, 2019) and LLM self-explanations (Madsen et al., 2024) have al...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.2 Limitations of Standard RAG | ano and Smith, 2019; Jain and Wallace, 2019) and LLM self-explanations (Madsen e...\n",
      "Citation: 2 Background ‚Üí 2.2 Limitations of Standard RAG\n",
      "\n",
      "--- Chunk 10 ---\n",
      "Type: ContextEnrichedChunk\n",
      "Section Path: ['2 Background', '2.3 Synthetic Training Data']\n",
      "Context: Section: 2 Background | Subsection: 2.3 Synthetic Training Data\n",
      "Content: Due to limited access and annotation restrictions, obtaining sentence-level labeled clinical dataset...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.3 Synthetic Training Data | Due to limited access and annotation restrictions, obtaining sentence-level labeled ...\n",
      "Citation: 2 Background ‚Üí 2.3 Synthetic Training Data\n",
      "\n",
      "... and 47 more chunks\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 chunks with their context\n",
    "n = 10\n",
    "print(f\"\\nüìù First {n} Chunks with Context:\")\n",
    "for i, chunk in enumerate(document.chunks[:n]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(f\"Type: {type(chunk).__name__}\")\n",
    "    print(f\"Section Path: {chunk.section_path}\")\n",
    "    print(f\"Context: {chunk.context_string}\")\n",
    "    print(f\"Content: {chunk.content[:100]}...\")\n",
    "\n",
    "    # Show enhanced content (what gets embedded)\n",
    "    if hasattr(chunk, 'get_enhanced_content'):\n",
    "        enhanced = chunk.get_enhanced_content()\n",
    "        print(f\"Enhanced: {enhanced[:150]}...\")\n",
    "\n",
    "    # Show citation context\n",
    "    if hasattr(chunk, 'get_citation_context'):\n",
    "        citation = chunk.get_citation_context()\n",
    "        print(f\"Citation: {citation}\")\n",
    "\n",
    "if len(document.chunks) > n:\n",
    "    print(f\"\\n... and {len(document.chunks) - n} more chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Context Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Context Distribution Analysis:\n",
      "\n",
      "üè∑Ô∏è  Chunks per Main Section:\n",
      "  1 Introduction: 5 chunks\n",
      "  2 Background: 5 chunks\n",
      "  3 Method: 16 chunks\n",
      "  4 Evaluation: 9 chunks\n",
      "  5 Ethical Considerations: 2 chunks\n",
      "  6 Limitations: 2 chunks\n",
      "  7 Conclusion: 18 chunks\n",
      "\n",
      "üìè Context String Statistics:\n",
      "  Average length: 35.0 chars\n",
      "  Min length: 21 chars\n",
      "  Max length: 67 chars\n",
      "\n",
      "üå≥ Unique Section Paths (12 total):\n",
      "  1 Introduction\n",
      "  2 Background ‚Üí 2.1 Dataset\n",
      "  2 Background ‚Üí 2.2 Limitations of Standard RAG\n",
      "  2 Background ‚Üí 2.3 Synthetic Training Data\n",
      "  3 Method ‚Üí 3.1 System Overview\n",
      "  3 Method ‚Üí 3.2 Evidence Extraction\n",
      "  3 Method ‚Üí 3.3 Synthetic Data Generation\n",
      "  3 Method ‚Üí 3.4 Answer Generation\n",
      "  4 Evaluation\n",
      "  5 Ethical Considerations\n",
      "  6 Limitations\n",
      "  7 Conclusion\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Context Distribution Analysis:\")\n",
    "\n",
    "# Analyze section distribution\n",
    "section_counts = {}\n",
    "context_lengths = []\n",
    "\n",
    "for chunk in document.chunks:\n",
    "    if hasattr(chunk, 'section_path') and chunk.section_path:\n",
    "        # Count chunks per section\n",
    "        main_section = chunk.section_path[0] if chunk.section_path else \"No Section\"\n",
    "        section_counts[main_section] = section_counts.get(main_section, 0) + 1\n",
    "\n",
    "        # Track context length\n",
    "        context_lengths.append(len(chunk.context_string))\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è  Chunks per Main Section:\")\n",
    "for section, count in sorted(section_counts.items()):\n",
    "    print(f\"  {section}: {count} chunks\")\n",
    "\n",
    "if context_lengths:\n",
    "    print(f\"\\nüìè Context String Statistics:\")\n",
    "    print(f\"  Average length: {sum(context_lengths)/len(context_lengths):.1f} chars\")\n",
    "    print(f\"  Min length: {min(context_lengths)} chars\")\n",
    "    print(f\"  Max length: {max(context_lengths)} chars\")\n",
    "\n",
    "# Show unique section paths\n",
    "unique_paths = set()\n",
    "for chunk in document.chunks:\n",
    "    if hasattr(chunk, 'section_path') and chunk.section_path:\n",
    "        path_str = \" ‚Üí \".join(chunk.section_path)\n",
    "        unique_paths.add(path_str)\n",
    "\n",
    "print(f\"\\nüå≥ Unique Section Paths ({len(unique_paths)} total):\")\n",
    "for path in sorted(unique_paths):\n",
    "    print(f\"  {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Embedding-Ready Content Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Embedding-Ready Content Examples:\n",
      "This shows what will actually be embedded for RAG retrieval.\n",
      "\n",
      "--- Example 1 ---\n",
      "Original: Modern question-answering (QA) and retrievalaugmented generation (RAG) systems play a vital role in ...\n",
      "Enhanced: Section: 1 Introduction | Modern question-answering (QA) and retrievalaugmented generation (RAG) systems play a vital role in many high-stakes domains for information extraction and generation tasks. ...\n",
      "Context adds: 26 chars\n",
      "\n",
      "--- Example 2 ---\n",
      "Original: incorrect information, commonly referred to as hallucinations (Ji et al., 2023; Madsen et al., 2024)...\n",
      "Enhanced: Section: 1 Introduction | incorrect information, commonly referred to as hallucinations (Ji et al., 2023; Madsen et al., 2024). We argue that a reliable QA system should guarantee complete traceabilit...\n",
      "Context adds: 26 chars\n",
      "\n",
      "--- Example 3 ---\n",
      "Original: trained generation , dynamically creating answer templates filled exclu-\n",
      "\n",
      "We participated in the Arc...\n",
      "Enhanced: Section: 1 Introduction | trained generation , dynamically creating answer templates filled exclu-\n",
      "\n",
      "We participated in the ArchEHR-QA 2025 shared task on grounded question answering (QA) from electron...\n",
      "Context adds: 26 chars\n",
      "\n",
      "--- Example 4 ---\n",
      "Original: arner et al., 2024), achieving performance comparable to the LLM extractor. Both extractors were the...\n",
      "Enhanced: Section: 1 Introduction | arner et al., 2024), achieving performance comparable to the LLM extractor. Both extractors were then fed into the same LLM template generator. Our solution achieved a score ...\n",
      "Context adds: 26 chars\n",
      "\n",
      "--- Example 5 ---\n",
      "Original: d train custom models. Additionally, we are releasing all the code on GitHub 2 under the MIT License...\n",
      "Enhanced: Section: 1 Introduction | d train custom models. Additionally, we are releasing all the code on GitHub 2 under the MIT License.\n",
      "\n",
      "The remainder of the paper discusses background (Section 2), method (Se...\n",
      "Context adds: 26 chars\n",
      "\n",
      "--- Example 6 ---\n",
      "Original: Early clinical QA datasets such as emrQA (Pampari et al., 2018) and CliCR (≈†uster and Daelemans, 201...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.1 Dataset | Early clinical QA datasets such as emrQA (Pampari et al., 2018) and CliCR (≈†uster and Daelemans, 2018) used fill-in-the-blank methods and lacked expli...\n",
      "Context adds: 50 chars\n",
      "\n",
      "--- Example 7 ---\n",
      "Original: sentence-level as essential , supplementary , or irrelevant . Answers must be concise (under 75 word...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.1 Dataset | sentence-level as essential , supplementary , or irrelevant . Answers must be concise (under 75 words) and explicitly cite relevant sentences....\n",
      "Context adds: 50 chars\n",
      "\n",
      "--- Example 8 ---\n",
      "Original: Standard RAG models, despite external grounding, still frequently hallucinate unsupported or contrad...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.2 Limitations of Standard RAG | Standard RAG models, despite external grounding, still frequently hallucinate unsupported or contradictory information (Ji et al.,...\n",
      "Context adds: 70 chars\n",
      "\n",
      "--- Example 9 ---\n",
      "Original: ano and Smith, 2019; Jain and Wallace, 2019) and LLM self-explanations (Madsen et al., 2024) have al...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.2 Limitations of Standard RAG | ano and Smith, 2019; Jain and Wallace, 2019) and LLM self-explanations (Madsen et al., 2024) have also been found unreliable. Our ...\n",
      "Context adds: 70 chars\n",
      "\n",
      "--- Example 10 ---\n",
      "Original: Due to limited access and annotation restrictions, obtaining sentence-level labeled clinical dataset...\n",
      "Enhanced: Section: 2 Background | Subsection: 2.3 Synthetic Training Data | Due to limited access and annotation restrictions, obtaining sentence-level labeled clinical datasets is challenging. Recent works add...\n",
      "Context adds: 66 chars\n",
      "\n",
      "--- Example 11 ---\n",
      "Original: Figure 1 depicts our system architecture. First, an extraction step identifies relevant sentences fr...\n",
      "Enhanced: Section: 3 Method | Subsection: 3.1 System Overview | Figure 1 depicts our system architecture. First, an extraction step identifies relevant sentences from the input (patient narrative, clinician que...\n",
      "Context adds: 54 chars\n",
      "\n",
      "--- Example 12 ---\n",
      "Original: We evaluated two extractors: (i) We prompted gemma-3-27b-it to explicitly label sentences as relevan...\n",
      "Enhanced: Section: 3 Method | Subsection: 3.2 Evidence Extraction | We evaluated two extractors: (i) We prompted gemma-3-27b-it to explicitly label sentences as relevant via a step-by-step process. (ii) We fine...\n",
      "Context adds: 58 chars\n",
      "\n",
      "üíæ ProcessedChunk Integration:\n",
      "Total processed chunks: 57\n",
      "\n",
      "Example ProcessedChunk:\n",
      "  Section title: Introduction\n",
      "  Enhanced content: Section: 1 Introduction | Modern question-answering (QA) and retrievalaugmented generation (RAG) systems play a vital role in many high-stakes domains...\n",
      "  Processing metadata: {'context_enriched': True, 'section_path': ['1 Introduction'], 'context_string': 'Section: 1 Introduction'}\n"
     ]
    }
   ],
   "source": [
    "print(\"üéØ Embedding-Ready Content Examples:\")\n",
    "print(\"This shows what will actually be embedded for RAG retrieval.\")\n",
    "\n",
    "# Show 3 examples of enhanced content\n",
    "for i, chunk in enumerate(document.chunks[:12]):\n",
    "    if hasattr(chunk, 'get_enhanced_content'):\n",
    "        print(f\"\\n--- Example {i+1} ---\")\n",
    "        print(f\"Original: {chunk.content[:100]}...\")\n",
    "        print(f\"Enhanced: {chunk.get_enhanced_content()[:200]}...\")\n",
    "        print(f\"Context adds: {len(chunk.get_enhanced_content()) - len(chunk.content)} chars\")\n",
    "\n",
    "# Show processed chunks (what goes to the index)\n",
    "print(f\"\\nüíæ ProcessedChunk Integration:\")\n",
    "total_processed = sum(len(chunk.processed_chunks) for chunk in document.chunks)\n",
    "print(f\"Total processed chunks: {total_processed}\")\n",
    "\n",
    "if document.chunks and document.chunks[0].processed_chunks:\n",
    "    pc = document.chunks[0].processed_chunks[0]\n",
    "    print(f\"\\nExample ProcessedChunk:\")\n",
    "    print(f\"  Section title: {pc.section_title}\")\n",
    "    print(f\"  Enhanced content: {pc.enhanced_content[:150]}...\")\n",
    "    print(f\"  Processing metadata: {pc.processing_metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: RAG Benefits Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ RAG Benefits Demonstration:\n",
      "Examples of how context enrichment improves retrieval...\n",
      "\n",
      "üîç Query: 'dataset'\n",
      "  Found 9 potential matches\n",
      "    Match 1 (Content+Context): 2 Background ‚Üí 2.1 Dataset\n",
      "      Content: Early clinical QA datasets such as emrQA (Pampari et al., 2018) and CliCR (≈†uste...\n",
      "    Match 2 (Context): 2 Background ‚Üí 2.1 Dataset\n",
      "      Content: sentence-level as essential , supplementary , or irrelevant . Answers must be co...\n",
      "\n",
      "üîç Query: 'background'\n",
      "  Found 6 potential matches\n",
      "    Match 1 (Context): 2 Background ‚Üí 2.1 Dataset\n",
      "      Content: Early clinical QA datasets such as emrQA (Pampari et al., 2018) and CliCR (≈†uste...\n",
      "    Match 2 (Context): 2 Background ‚Üí 2.1 Dataset\n",
      "      Content: sentence-level as essential , supplementary , or irrelevant . Answers must be co...\n",
      "\n",
      "üîç Query: 'method'\n",
      "  Found 28 potential matches\n",
      "    Match 1 (Content+Context): 3 Method ‚Üí 3.4 Answer Generation\n",
      "      Content: repair of his ruptured thoracoabdominal aortic aneurysm. |1| -He was immediately...\n",
      "    Match 2 (Content+Context): 3 Method ‚Üí 3.4 Answer Generation\n",
      "      Content: ated by our verbatim method, inserting evidence sentences verbatim into a dynami...\n",
      "\n",
      "üîç Query: 'evaluation'\n",
      "  Found 12 potential matches\n",
      "    Match 1 (Context): 4 Evaluation\n",
      "      Content: We evaluated our pipeline in the ArchEHR-QA 2025 shared task (Soni and Demner-Fu...\n",
      "    Match 2 (Context): 4 Evaluation\n",
      "      Content: s through BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), BERTScore (Zhang et a...\n",
      "\n",
      "üîç Query: 'limitations'\n",
      "  Found 4 potential matches\n",
      "    Match 1 (Content+Context): 6 Limitations\n",
      "      Content: Our verbatim RAG pipeline explicitly cites source sentences to mitigate hallucin...\n",
      "    Match 2 (Context): 2 Background ‚Üí 2.2 Limitations of Standard RAG\n",
      "      Content: Standard RAG models, despite external grounding, still frequently hallucinate un...\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ RAG Benefits Demonstration:\")\n",
    "print(\"Examples of how context enrichment improves retrieval...\")\n",
    "\n",
    "# Simulate search scenarios\n",
    "search_terms = [\n",
    "    \"dataset\",\n",
    "    \"background\",\n",
    "    \"method\",\n",
    "    \"evaluation\",\n",
    "    \"limitations\"\n",
    "]\n",
    "\n",
    "for term in search_terms:\n",
    "    print(f\"\\nüîç Query: '{term}'\")\n",
    "    matches = []\n",
    "\n",
    "    for chunk in document.chunks:\n",
    "        if hasattr(chunk, 'get_enhanced_content'):\n",
    "            enhanced = chunk.get_enhanced_content().lower()\n",
    "            if term.lower() in enhanced:\n",
    "                # Calculate relevance score (simple approach)\n",
    "                content_match = term.lower() in chunk.content.lower()\n",
    "                context_match = term.lower() in chunk.context_string.lower()\n",
    "\n",
    "                matches.append({\n",
    "                    'chunk': chunk,\n",
    "                    'content_match': content_match,\n",
    "                    'context_match': context_match,\n",
    "                    'both': content_match and context_match\n",
    "                })\n",
    "\n",
    "    if matches:\n",
    "        print(f\"  Found {len(matches)} potential matches\")\n",
    "\n",
    "        # Show best matches\n",
    "        best_matches = sorted(matches, key=lambda x: (x['both'], x['context_match'], x['content_match']), reverse=True)[:2]\n",
    "\n",
    "        for i, match in enumerate(best_matches):\n",
    "            chunk = match['chunk']\n",
    "            match_type = \"Content+Context\" if match['both'] else (\"Context\" if match['context_match'] else \"Content\")\n",
    "            print(f\"    Match {i+1} ({match_type}): {chunk.get_citation_context()}\")\n",
    "            print(f\"      Content: {chunk.content[:80]}...\")\n",
    "    else:\n",
    "        print(f\"  No matches found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Context-Enriched Processing Summary:\n",
      "==================================================\n",
      "\n",
      "‚úÖ Successfully processed document with context enrichment\n",
      "  üìÑ Document: Verbatim RAG ACL Paper\n",
      "  üß© Total chunks: 57\n",
      "  üè∑Ô∏è  Context-enriched chunks: 57\n",
      "  üìö Unique sections: 7\n",
      "\n",
      "üéØ Key Benefits for RAG:\n",
      "  ‚Ä¢ Each chunk contains full hierarchical context\n",
      "  ‚Ä¢ Section information embedded with content\n",
      "  ‚Ä¢ Better retrieval through context matching\n",
      "  ‚Ä¢ Rich citation context for answers\n",
      "  ‚Ä¢ Backward compatible with existing VerbatimRAG\n",
      "\n",
      "üöÄ Ready for:\n",
      "  ‚Ä¢ Integration with VerbatimIndex\n",
      "  ‚Ä¢ Embedding generation with context\n",
      "  ‚Ä¢ Enhanced RAG retrieval testing\n",
      "\n",
      "üßπ Test complete - ready for production integration!\n"
     ]
    }
   ],
   "source": [
    "print(\"üìã Context-Enriched Processing Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully processed document with context enrichment\")\n",
    "print(f\"  üìÑ Document: {document.title}\")\n",
    "print(f\"  üß© Total chunks: {len(document.chunks)}\")\n",
    "\n",
    "# Count context-enriched chunks\n",
    "enriched_count = sum(1 for chunk in document.chunks if hasattr(chunk, 'section_path') and chunk.section_path)\n",
    "print(f\"  üè∑Ô∏è  Context-enriched chunks: {enriched_count}\")\n",
    "\n",
    "# Show unique sections\n",
    "sections = set()\n",
    "for chunk in document.chunks:\n",
    "    if hasattr(chunk, 'section_path') and chunk.section_path:\n",
    "        sections.add(chunk.section_path[0])\n",
    "print(f\"  üìö Unique sections: {len(sections)}\")\n",
    "\n",
    "print(f\"\\nüéØ Key Benefits for RAG:\")\n",
    "print(f\"  ‚Ä¢ Each chunk contains full hierarchical context\")\n",
    "print(f\"  ‚Ä¢ Section information embedded with content\")\n",
    "print(f\"  ‚Ä¢ Better retrieval through context matching\")\n",
    "print(f\"  ‚Ä¢ Rich citation context for answers\")\n",
    "print(f\"  ‚Ä¢ Backward compatible with existing VerbatimRAG\")\n",
    "\n",
    "print(f\"\\nüöÄ Ready for:\")\n",
    "print(f\"  ‚Ä¢ Integration with VerbatimIndex\")\n",
    "print(f\"  ‚Ä¢ Embedding generation with context\")\n",
    "print(f\"  ‚Ä¢ Enhanced RAG retrieval testing\")\n",
    "\n",
    "print(f\"\\nüßπ Test complete - ready for production integration!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
