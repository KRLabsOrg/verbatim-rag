{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VerbatimRAG + Context-Enriched Integration Test\n",
    "\n",
    "This notebook tests the full integration of ContextEnrichedProcessor with the VerbatimRAG system.\n",
    "It demonstrates how hierarchical context enrichment improves retrieval accuracy and maintains\n",
    "verbatim span extraction capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Initialize the environment and load required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:53:52.968723Z",
     "start_time": "2025-08-07T13:53:52.960163Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Fix OpenMP conflict\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Load environment variables from .env.local\n",
    "load_dotenv(project_root / '.env.local', override=True)\n",
    "\n",
    "# Check if an API key is loaded\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    print(\"‚ö†Ô∏è  Warning: OPENAI_API_KEY not found. Please set it in .env.local\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key loaded\")\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(\"‚úÖ Setup complete\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key loaded\n",
      "Project root: /Users/paulschmitt/DataspellProjects/verbatim-rag\n",
      "‚úÖ Setup complete\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:53:57.488176Z",
     "start_time": "2025-08-07T13:53:53.080568Z"
    }
   },
   "source": [
    "from verbatim_rag.ingestion.context_enriched_processor import ContextEnrichedProcessor\n",
    "from verbatim_rag.core import VerbatimRAG\n",
    "from verbatim_rag.index import VerbatimIndex\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Process Document with Context Enrichment\n",
    "\n",
    "This test verifies that the ContextEnrichedProcessor can successfully process a PDF document \n",
    "and create context-enriched chunks. Each chunk will include hierarchical context information \n",
    "(section paths, titles, etc.) that will help with more accurate retrieval."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:54:22.788509Z",
     "start_time": "2025-08-07T13:53:57.501443Z"
    }
   },
   "source": [
    "# Test document path\n",
    "pdf_path = project_root / \"data\" / \"acl_papers\" / \"Lexical_grammar_induction.pdf\"\n",
    "\n",
    "# Create context-enriched processor optimized for RAG\n",
    "processor = ContextEnrichedProcessor.for_rag(\n",
    "    chunk_size=384,  # Smaller chunks for better retrieval\n",
    "    overlap=50\n",
    ")\n",
    "\n",
    "# Process document\n",
    "print(\"üìÑ Processing document with context enrichment...\")\n",
    "document = processor.process_file(pdf_path, title=\"Lexical Grammar Induction\")\n",
    "\n",
    "print(f\"‚úÖ Document processed successfully!\")\n",
    "print(f\"  Title: {document.title}\")\n",
    "print(f\"  Chunks: {len(document.chunks)}\")\n",
    "print(f\"  Content type: {document.content_type}\")\n",
    "\n",
    "# Show chunk types\n",
    "enriched_chunks = [c for c in document.chunks if hasattr(c, 'section_path')]\n",
    "print(f\"  Context-enriched chunks: {len(enriched_chunks)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Processing document with context enrichment...\n",
      "‚úÖ Document processed successfully!\n",
      "  Title: Lexical Grammar Induction\n",
      "  Chunks: 124\n",
      "  Content type: DocumentType.PDF\n",
      "  Context-enriched chunks: 124\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Create VerbatimIndex with Context-Enriched Chunks\n",
    "\n",
    "This test creates a VerbatimIndex using the context-enriched document chunks from Test 1. \n",
    "The index will store both the embeddings and the hierarchical context information, \n",
    "enabling more precise document retrieval."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:54:28.951016Z",
     "start_time": "2025-08-07T13:54:22.800244Z"
    }
   },
   "source": [
    "# Create VerbatimIndex with context-enriched chunks\n",
    "print(\"üóÇÔ∏è Creating VerbatimIndex with context-enriched chunks...\")\n",
    "\n",
    "# Initialize index with OpenAI embeddings and FAISS vector store\n",
    "index = VerbatimIndex(dense_model=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Add the context-enriched document to the index (using add_documents method)\n",
    "print(\"üìù Adding document to index...\")\n",
    "index.add_documents([document])\n",
    "\n",
    "print(f\"‚úÖ Index created successfully!\")\n",
    "print(f\"  Vector store type: {type(index.vector_store).__name__}\")\n",
    "print(f\"  Embedding provider: {type(index.dense_provider).__name__}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÇÔ∏è Creating VerbatimIndex with context-enriched chunks...\n",
      "üìù Adding document to index...\n",
      "‚úÖ Index created successfully!\n",
      "  Vector store type: LocalMilvusStore\n",
      "  Embedding provider: SentenceTransformersProvider\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Initialize VerbatimRAG System\n",
    "\n",
    "This test initializes the complete VerbatimRAG system using the context-enriched index. \n",
    "It verifies that the RAG system can properly integrate with the hierarchically structured \n",
    "document chunks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:54:28.979875Z",
     "start_time": "2025-08-07T13:54:28.960546Z"
    }
   },
   "source": [
    "# Initialize VerbatimRAG with the context-enriched index\n",
    "print(\"ü§ñ Initializing VerbatimRAG system...\")\n",
    "\n",
    "rag = VerbatimRAG(\n",
    "    index=index  # Pass the index as required parameter\n",
    ")\n",
    "\n",
    "print(\"‚úÖ VerbatimRAG initialized successfully!\")\n",
    "\n",
    "# Test that the index is working by doing a simple search\n",
    "try:\n",
    "    test_results = index.search(\"verbatim\", k=3)\n",
    "    print(f\"  Index working: Found {len(test_results)} results for test query\")\n",
    "except Exception as e:\n",
    "    print(f\"  Index test failed: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing VerbatimRAG system...\n",
      "‚úÖ VerbatimRAG initialized successfully!\n",
      "  Index working: Found 3 results for test query\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Query with Context-Enriched Retrieval\n",
    "\n",
    "This test performs queries against the VerbatimRAG system to verify that context-enriched \n",
    "chunks improve retrieval accuracy. We test multiple types of queries to demonstrate how \n",
    "hierarchical context helps with finding relevant information."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:55:14.825059Z",
     "start_time": "2025-08-07T13:54:28.993605Z"
    }
   },
   "source": [
    "# Test queries that should benefit from hierarchical context\n",
    "test_queries = [\n",
    "    \"What dataset was used in this study?\",\n",
    "    \"What are the limitations of standard RAG systems?\", \n",
    "    \"How does the method work?\",\n",
    "    \"What evaluation metrics were used?\",\n",
    "    \"What are the main contributions of this work?\"\n",
    "]\n",
    "\n",
    "print(\"üîç Testing queries with context-enriched retrieval...\")\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n--- Query {i} ---\")\n",
    "    print(f\"Question: {query}\")\n",
    "    \n",
    "    try:\n",
    "        # Get response from VerbatimRAG\n",
    "        response = rag.query(question=query)\n",
    "        \n",
    "        print(f\"Answer: {response.answer[:200]}...\")\n",
    "        print(f\"Source documents: {len(response.documents)} documents cited\")\n",
    "        \n",
    "        # Show retrieved documents with their context\n",
    "        print(\"Retrieved documents:\")\n",
    "        for j, doc in enumerate(response.documents[:2]):\n",
    "            print(f\"  {j+1}. Document: '{doc.title}'\")\n",
    "            if hasattr(doc, 'highlights') and doc.highlights:\n",
    "                print(f\"     Highlights: {len(doc.highlights)} spans\")\n",
    "                for k, highlight in enumerate(doc.highlights[:1]):\n",
    "                    print(f\"       - {highlight.text[:80]}...\")\n",
    "            else:\n",
    "                print(f\"     Content preview: {doc.content[:80] if hasattr(doc, 'content') else 'N/A'}...\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing queries with context-enriched retrieval...\n",
      "\n",
      "--- Query 1 ---\n",
      "Question: What dataset was used in this study?\n",
      "Answer: Thanks for your question! Based on the documents, here are the key points:\n",
      "\n",
      "‚Ä¢ Dataset\n",
      "‚Ä¢ 6 datasets\n",
      "‚Ä¢ dataset\n",
      "‚Ä¢ Russian and Spanish out-of-domain datasets derived from Wikipedia\n",
      "‚Ä¢ the two datasets\n",
      "‚Ä¢ BM...\n",
      "Source documents: 5 documents cited\n",
      "Retrieved documents:\n",
      "  1. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 1 spans\n",
      "       - Dataset...\n",
      "  2. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 3 spans\n",
      "       - Russian and Spanish out-of-domain datasets derived from Wikipedia...\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Query 2 ---\n",
      "Question: What are the limitations of standard RAG systems?\n",
      "Answer: Thanks for your question! Based on the documents, here are the key points:\n",
      "\n",
      "‚Ä¢ the number of patterns matching a subgraph of N +1 nodes increases from 2 N to 3 N\n",
      "‚Ä¢ the number of IRTG rules that under o...\n",
      "Source documents: 5 documents cited\n",
      "Retrieved documents:\n",
      "  1. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 2 spans\n",
      "       - the number of IRTG rules that under our original approach would be included in a...\n",
      "  2. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 1 spans\n",
      "       - but exploring the effects of weighting schemes that could in some cases countera...\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Query 3 ---\n",
      "Question: How does the method work?\n",
      "Answer: Thanks for your question! Based on the documents, here are the key points:\n",
      "\n",
      "‚Ä¢ the graph operations building the particular pattern\n",
      "‚Ä¢ the string operations concatenating the corresponding words in the ...\n",
      "Source documents: 5 documents cited\n",
      "Retrieved documents:\n",
      "  1. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 2 spans\n",
      "       - the string operations concatenating the corresponding words in the order that is...\n",
      "  2. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 2 spans\n",
      "       - The word reordering task is then equivalent to parsing graphs and decoding strin...\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Query 4 ---\n",
      "Question: What evaluation metrics were used?\n",
      "Answer: Thanks for your question! Based on the documents, here are the key points:\n",
      "\n",
      "‚Ä¢ automatic evaluation metrics\n",
      "‚Ä¢ average scores (Ave)\n",
      "‚Ä¢ average standardized scores (Ave. z)\n",
      "‚Ä¢ meaning similarity\n",
      "‚Ä¢ readabil...\n",
      "Source documents: 5 documents cited\n",
      "Retrieved documents:\n",
      "  1. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 1 spans\n",
      "       - automatic evaluation metrics...\n",
      "  2. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 4 spans\n",
      "       - average standardized scores (Ave. z)...\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Query 5 ---\n",
      "Question: What are the main contributions of this work?\n",
      "Answer: Thanks for your question! Based on the documents, here are the key points:\n",
      "\n",
      "‚Ä¢ The 2020 Surface Realization Shared Task (Mille et al., 2020) involves mapping Universal Dependency representations to raw...\n",
      "Source documents: 5 documents cited\n",
      "Retrieved documents:\n",
      "  1. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 3 spans\n",
      "       - The input data in the shallow track consists of UD-annotated sentences for 11 la...\n",
      "  2. Document: 'Lexical Grammar Induction'\n",
      "     Highlights: 3 spans\n",
      "       - extend the word order restoration component of Kov¬¥ acs et al. (2019) by making ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Analyze Context Benefits\n",
    "\n",
    "This test analyzes the search results to understand how context enrichment affects chunk \n",
    "retrieval. It examines the retrieved chunks' metadata and content to demonstrate the \n",
    "benefits of hierarchical context."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:55:14.872021Z",
     "start_time": "2025-08-07T13:55:14.849286Z"
    }
   },
   "source": [
    "# Test specific query to compare context benefits\n",
    "query = \"What are the limitations mentioned in the paper?\"\n",
    "\n",
    "print(f\"üî¨ Context Analysis: '{query}'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Retrieve top chunks\n",
    "try:\n",
    "    results = index.search(query, k=5)\n",
    "    \n",
    "    print(f\"\\nüìä Retrieved {len(results)} chunks:\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. Score: {result.score:.3f}\")\n",
    "        print(f\"   Content: {result.text[:120]}...\")\n",
    "        \n",
    "        # Check metadata for context information\n",
    "        if result.metadata:\n",
    "            if 'title' in result.metadata:\n",
    "                print(f\"   Document: {result.metadata['title']}\")\n",
    "            if 'chunk_type' in result.metadata:\n",
    "                print(f\"   Chunk type: {result.metadata['chunk_type']}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Search error: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Context Analysis: 'What are the limitations mentioned in the paper?'\n",
      "============================================================\n",
      "\n",
      "üìä Retrieved 5 chunks:\n",
      "\n",
      "1. Score: 0.257\n",
      "   Content: Lexical Grammar Induction | Section: 3 SZTAKI Institute of Computer Science andras@kornai.com | Subsection: 3.1 Motivati...\n",
      "   Document: Lexical Grammar Induction\n",
      "   Chunk type: paragraph\n",
      "\n",
      "2. Score: 0.228\n",
      "   Content: Lexical Grammar Induction | Section: 4 Hierarchical surface realization | or which parsing did not finish in 60 seconds,...\n",
      "   Document: Lexical Grammar Induction\n",
      "   Chunk type: section\n",
      "\n",
      "3. Score: 0.217\n",
      "   Content: Lexical Grammar Induction | Section: 5 Overall architecture | periments. In case of a timeout, a new IRTG is generated k...\n",
      "   Document: Lexical Grammar Induction\n",
      "   Chunk type: section\n",
      "\n",
      "4. Score: 0.209\n",
      "   Content: Lexical Grammar Induction | Section: 4 Hierarchical surface realization | rguments of a predicate separated by an interv...\n",
      "   Document: Lexical Grammar Induction\n",
      "   Chunk type: section\n",
      "\n",
      "5. Score: 0.205\n",
      "   Content: Lexical Grammar Induction | Section: 3 SZTAKI Institute of Computer Science andras@kornai.com | Subsection: 3.1 Motivati...\n",
      "   Document: Lexical Grammar Induction\n",
      "   Chunk type: paragraph\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6: Span Extraction with Context\n",
    "\n",
    "This test verifies that the VerbatimRAG span extraction functionality works correctly \n",
    "with context-enriched chunks. It ensures that the hierarchical context doesn't interfere \n",
    "with the verbatim span extraction process and that citations are properly generated."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:55:25.308994Z",
     "start_time": "2025-08-07T13:55:14.886642Z"
    }
   },
   "source": [
    "# Test span extraction to ensure context doesn't interfere\n",
    "query = \"What evaluation metrics were used?\"\n",
    "\n",
    "print(f\"üéØ Span Extraction Test: '{query}'\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Get a full response with span extraction\n",
    "    response = rag.query(question=query)\n",
    "    \n",
    "    print(f\"\\nüìù Answer: {response.answer[:200]}...\")\n",
    "    print(f\"\\nüìö Citations ({len(response.structured_answer.citations)}):\")\n",
    "    \n",
    "    for i, citation in enumerate(response.structured_answer.citations[:5]):\n",
    "        print(f\"\\n{i+1}. Citation:\")\n",
    "        print(f\"   Extracted span: {citation.text[:100]}...\")\n",
    "        print(f\"   Document index: {citation.doc_index}\")\n",
    "        print(f\"   Highlight index: {citation.highlight_index}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Span extraction error: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Span Extraction Test: 'What evaluation metrics were used?'\n",
      "==================================================\n",
      "\n",
      "üìù Answer: Thanks for your question! Based on the documents, here are the key points:\n",
      "\n",
      "‚Ä¢ using automatic evaluation metrics\n",
      "‚Ä¢ average scores (Ave)\n",
      "‚Ä¢ average standardized scores (Ave. z)\n",
      "‚Ä¢ meaning similarity\n",
      "‚Ä¢ re...\n",
      "\n",
      "üìö Citations (12):\n",
      "\n",
      "1. Citation:\n",
      "   Extracted span: using automatic evaluation metrics...\n",
      "   Document index: 0\n",
      "   Highlight index: 0\n",
      "\n",
      "2. Citation:\n",
      "   Extracted span: average standardized scores (Ave. z)...\n",
      "   Document index: 1\n",
      "   Highlight index: 0\n",
      "\n",
      "3. Citation:\n",
      "   Extracted span: readability evaluations...\n",
      "   Document index: 1\n",
      "   Highlight index: 1\n",
      "\n",
      "4. Citation:\n",
      "   Extracted span: average scores (Ave)...\n",
      "   Document index: 1\n",
      "   Highlight index: 2\n",
      "\n",
      "5. Citation:\n",
      "   Extracted span: meaning similarity...\n",
      "   Document index: 1\n",
      "   Highlight index: 3\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
